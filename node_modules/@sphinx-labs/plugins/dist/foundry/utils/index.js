"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.validateProposalNetworks = exports.parseScriptFunctionCalldata = exports.isDeploymentInfo = exports.assertValidVersions = exports.parseNestedContractDeployments = exports.isCreate2AccountAccess = exports.writeSystemContracts = exports.findFullyQualifiedNameForAddress = exports.findFullyQualifiedNameForInitCode = exports.replaceEnvVariables = exports.getNetworkGasEstimate = exports.getEstimatedGas = exports.convertLibraryFormat = exports.findFunctionFragment = exports.readInterface = exports.readFoundrySingleChainDryRun = exports.readFoundrySingleChainBroadcast = exports.getFoundrySingleChainDryRunPath = exports.readFoundryMultiChainDryRun = exports.isFoundrySingleChainDryRun = exports.isFoundryMultiChainDryRun = exports.callForgeScriptFunction = exports.getForgeScriptArgs = exports.getSphinxConfigFromScript = exports.isInitCodeMatch = exports.inferSolcVersion = exports.makeGetConfigArtifacts = exports.assertNoLinkedLibraries = exports.compile = exports.getInitCodeWithArgsArray = exports.readContractArtifact = exports.messageMultipleArtifactsFound = exports.messageArtifactNotFound = exports.streamBuildInfo = exports.streamBuildInfoCacheContracts = void 0;
const path_1 = __importStar(require("path"));
const util_1 = require("util");
const fs_1 = require("fs");
const child_process_1 = require("child_process");
const utils_1 = require("@sphinx-labs/core/dist/utils");
const semver_1 = require("semver");
const stream_chain_1 = __importDefault(require("stream-chain"));
const stream_json_1 = __importDefault(require("stream-json"));
const Ignore_1 = require("stream-json/filters/Ignore");
const Pick_1 = require("stream-json/filters/Pick");
const StreamObject_1 = require("stream-json/streamers/StreamObject");
const StreamValues_1 = require("stream-json/streamers/StreamValues");
const core_1 = require("@sphinx-labs/core");
const contracts_1 = require("@sphinx-labs/contracts");
const ethers_1 = require("ethers");
const simulate_1 = require("../../hardhat/simulate");
const trim_1 = require("./trim");
const utils_2 = require("../../cli/utils");
const error_messages_1 = require("../error-messages");
const readFileAsync = (0, util_1.promisify)(fs_1.readFile);
const streamBuildInfoCacheContracts = async (filePath) => {
    const pipeline = new stream_chain_1.default([
        (0, fs_1.createReadStream)(filePath),
        (0, stream_json_1.default)(),
        (0, Pick_1.pick)({ filter: 'output' }),
        (0, Pick_1.pick)({ filter: 'contracts' }),
        (0, StreamObject_1.streamObject)(),
        (data) => {
            const sourceName = data.key;
            const contracts = [];
            for (const [contractName, contract] of Object.entries(data.value)) {
                const iface = new ethers_1.ethers.Interface(contract.abi);
                const constructorFragment = iface.fragments.find(ethers_1.ConstructorFragment.isFragment);
                contracts.push({
                    fullyQualifiedName: `${sourceName}:${contractName}`,
                    bytecode: (0, contracts_1.add0x)(contract.evm.bytecode.object),
                    linkReferences: contract.evm.bytecode.linkReferences,
                    constructorFragment,
                });
            }
            return contracts;
        },
    ]);
    const buildInfoCacheContracts = [];
    pipeline.on('data', (name) => {
        buildInfoCacheContracts.push(name);
    });
    await new Promise((resolve) => pipeline.on('finish', resolve));
    return buildInfoCacheContracts;
};
exports.streamBuildInfoCacheContracts = streamBuildInfoCacheContracts;
const streamBuildInfo = async (filePath) => {
    const pipeline = new stream_chain_1.default([
        (0, fs_1.createReadStream)(filePath),
        (0, stream_json_1.default)(),
        (0, Ignore_1.ignore)({ filter: 'output' }),
        (0, StreamValues_1.streamValues)(),
        (data) => {
            return data;
        },
    ]);
    let buildInfo;
    pipeline.on('data', (b) => {
        buildInfo = b.value;
    });
    await new Promise((resolve) => pipeline.on('finish', resolve));
    return buildInfo;
};
exports.streamBuildInfo = streamBuildInfo;
const messageArtifactNotFound = (fullyQualifiedName) => {
    return (`Could not find artifact for: ${fullyQualifiedName}. Please reload your artifacts by running:\n` +
        `forge clean`);
};
exports.messageArtifactNotFound = messageArtifactNotFound;
const messageMultipleArtifactsFound = (contractNameOrFullyQualifiedName) => {
    return (`Detected multiple contracts with the name ${contractNameOrFullyQualifiedName}. Please use the fully \n` +
        `qualified name for this contract in the format: 'path/to/file/File.sol:MyContract'`);
};
exports.messageMultipleArtifactsFound = messageMultipleArtifactsFound;
const readContractArtifact = async (fullyQualifiedName, projectRoot, artifactFolder) => {
    const [sourceFileName, contractName] = path_1.default
        .basename(fullyQualifiedName)
        .split(':');
    const sourceDirectoryPath = (0, path_1.dirname)(fullyQualifiedName);
    const relativeSourceDirPath = path_1.default.relative(projectRoot, sourceDirectoryPath);
    let pathParts = relativeSourceDirPath.split(path_1.default.sep);
    while (pathParts.length > 0) {
        const joinedPathParts = pathParts.join(path_1.default.sep);
        const currentPath = (0, path_1.join)(artifactFolder, joinedPathParts, sourceFileName, `${contractName}.json`);
        if ((0, fs_1.existsSync)(currentPath)) {
            return (0, contracts_1.parseFoundryContractArtifact)(JSON.parse(await readFileAsync(currentPath, 'utf8')));
        }
        pathParts = pathParts.slice(1);
    }
    const shortestPath = (0, path_1.join)(artifactFolder, sourceFileName, `${contractName}.json`);
    if ((0, fs_1.existsSync)(shortestPath)) {
        return (0, contracts_1.parseFoundryContractArtifact)(JSON.parse(await readFileAsync(shortestPath, 'utf8')));
    }
    throw new Error((0, exports.messageArtifactNotFound)(fullyQualifiedName));
};
exports.readContractArtifact = readContractArtifact;
const getInitCodeWithArgsArray = (accountAccesses) => {
    const flat = accountAccesses.flatMap((access) => [
        access.root,
        ...access.nested,
    ]);
    return flat
        .filter((accountAccess) => accountAccess.kind === contracts_1.AccountAccessKind.Create)
        .map((accountAccess) => accountAccess.data);
};
exports.getInitCodeWithArgsArray = getInitCodeWithArgsArray;
const compile = (silent, force, buildInfo) => {
    const forgeBuildArgs = ['build'];
    if (silent) {
        forgeBuildArgs.push('--silent');
    }
    if (force) {
        forgeBuildArgs.push('--force');
    }
    if (buildInfo) {
        forgeBuildArgs.push('--build-info');
    }
    const { status: compilationStatus } = (0, child_process_1.spawnSync)(`forge`, forgeBuildArgs, {
        stdio: 'inherit',
    });
    if (compilationStatus !== 0) {
        process.exit(1);
    }
};
exports.compile = compile;
const assertNoLinkedLibraries = async (scriptPath, cachePath, artifactFolder, projectRoot, targetContract) => {
    const fullyQualifiedName = targetContract
        ? `${scriptPath}:${targetContract}`
        :
            findFullyQualifiedNames(scriptPath, cachePath, projectRoot)[0];
    const artifact = await (0, exports.readContractArtifact)(fullyQualifiedName, projectRoot, artifactFolder);
    const containsLibrary = Object.keys(artifact.linkReferences).length > 0 ||
        Object.keys(artifact.deployedLinkReferences).length > 0;
    if (containsLibrary) {
        throw new Error(`Detected linked library in: ${fullyQualifiedName}\n` +
            `You must remove all linked libraries in this file because Sphinx currently doesn't support them.`);
    }
};
exports.assertNoLinkedLibraries = assertNoLinkedLibraries;
const findFullyQualifiedNames = (rawSourceName, cachePath, projectRoot) => {
    const buildInfoCacheFilePath = (0, path_1.join)(cachePath, 'sphinx-cache.json');
    const sourceName = (0, path_1.relative)(projectRoot, rawSourceName);
    const buildInfoCache = JSON.parse((0, fs_1.readFileSync)(buildInfoCacheFilePath, 'utf8'));
    const sortedCachedFiles = Object.values(buildInfoCache).sort((a, b) => b.time - a.time);
    for (const { contracts } of sortedCachedFiles) {
        const fullyQualifiedNames = contracts
            .filter((contract) => contract.fullyQualifiedName.startsWith(sourceName))
            .map((contract) => contract.fullyQualifiedName);
        if (fullyQualifiedNames.length > 0) {
            return fullyQualifiedNames;
        }
    }
    return [];
};
const makeGetConfigArtifacts = (artifactFolder, buildInfoFolder, projectRoot, cachePath) => {
    return async (initCodeWithArgsIncludingDuplicates) => {
        const initCodeWithArgsArray = Array.from(new Set(initCodeWithArgsIncludingDuplicates));
        const buildInfoCacheFilePath = (0, path_1.join)(cachePath, 'sphinx-cache.json');
        let buildInfoCache = (0, fs_1.existsSync)(buildInfoCacheFilePath)
            ? JSON.parse((0, fs_1.readFileSync)(buildInfoCacheFilePath, 'utf8'))
            : {};
        const buildInfoPath = (0, path_1.join)(buildInfoFolder);
        const buildInfoFileNames = (0, fs_1.readdirSync)(buildInfoPath).filter((fileName) => {
            return fileName.endsWith('.json');
        });
        const cachedNames = Object.keys(buildInfoCache);
        if (buildInfoFileNames.length === 1 &&
            !cachedNames.includes(buildInfoFileNames[0])) {
            buildInfoCache = {};
        }
        for (const cachedName of cachedNames) {
            if (!buildInfoFileNames.includes(cachedName)) {
                delete buildInfoCache[cachedName];
            }
        }
        const buildInfoFileNamesWithTime = buildInfoFileNames
            .map((fileName) => ({
            name: fileName,
            time: (0, fs_1.statSync)(path_1.default.join(buildInfoPath, fileName)).mtime.getTime(),
        }))
            .sort((a, b) => b.time - a.time);
        for (const file of buildInfoFileNamesWithTime) {
            if (buildInfoCache[file.name]?.time &&
                buildInfoCache[file.name]?.time !== file.time) {
                buildInfoCache[file.name].time = file.time;
            }
            else if (!buildInfoCache[file.name]) {
                buildInfoCache[file.name] = {
                    name: file.name,
                    time: file.time,
                    contracts: await (0, exports.streamBuildInfoCacheContracts)((0, path_1.join)(buildInfoFolder, file.name)),
                };
            }
        }
        const sortedCachedFiles = Object.values(buildInfoCache).sort((a, b) => b.time - a.time);
        const toReadFiles = [];
        const localBuildInfoCache = {};
        const fullyQualifiedNamePromises = initCodeWithArgsArray.map(async (initCodeWithArgs) => {
            for (const file of sortedCachedFiles) {
                const contract = file.contracts.find((ct) => {
                    const { bytecode, constructorFragment, linkReferences } = ct;
                    return (0, exports.isInitCodeMatch)(initCodeWithArgs, {
                        bytecode,
                        linkReferences,
                        constructorFragment,
                    });
                });
                if (contract) {
                    if (!toReadFiles.includes(file.name)) {
                        toReadFiles.push(file.name);
                    }
                    const artifact = await (0, exports.readContractArtifact)(contract.fullyQualifiedName, projectRoot, artifactFolder);
                    return {
                        fullyQualifiedName: contract.fullyQualifiedName,
                        artifact,
                        buildInfoName: file.name,
                    };
                }
            }
        });
        const resolved = (await Promise.all(fullyQualifiedNamePromises)).filter(utils_1.isDefined);
        await Promise.all(toReadFiles.map(async (file) => {
            const fullFilePath = (0, path_1.join)(buildInfoFolder, file);
            if (!(0, fs_1.existsSync)(fullFilePath)) {
                if ((0, fs_1.existsSync)(buildInfoCacheFilePath)) {
                    (0, fs_1.unlinkSync)(buildInfoCacheFilePath);
                }
                throw new Error(`Build info cache is outdated, please run 'forge build --force' then try again.`);
            }
            else {
                const buildInfo = await (0, exports.streamBuildInfo)(fullFilePath);
                localBuildInfoCache[file] = buildInfo;
            }
        }));
        const completeArtifacts = resolved.map((artifactInfo) => {
            return {
                ...artifactInfo,
                buildInfo: (0, trim_1.trimObjectToType)(localBuildInfoCache[artifactInfo.buildInfoName], trim_1.BuildInfoTemplate),
            };
        });
        (0, fs_1.writeFileSync)(buildInfoCacheFilePath, JSON.stringify(buildInfoCache, null, 2));
        const configArtifacts = {};
        const buildInfos = {};
        for (const { fullyQualifiedName, artifact, buildInfo, } of completeArtifacts) {
            buildInfo.solcLongVersion = (0, utils_1.formatSolcLongVersion)(buildInfo.solcLongVersion);
            buildInfos[buildInfo.id] = buildInfo;
            configArtifacts[fullyQualifiedName] = {
                artifact,
                buildInfoId: buildInfo.id,
            };
        }
        return { configArtifacts, buildInfos };
    };
};
exports.makeGetConfigArtifacts = makeGetConfigArtifacts;
const inferSolcVersion = async () => {
    const defaultSolcVersion = '0.8.19';
    try {
        const solcVersionOutput = await (0, utils_1.execAsync)('solc --version');
        const solcVersionRaw = solcVersionOutput.stdout.split('Version: ')[1];
        const parsed = (0, semver_1.parse)(solcVersionRaw);
        return parsed ? parsed.toString() : defaultSolcVersion;
    }
    catch (err) {
        return defaultSolcVersion;
    }
};
exports.inferSolcVersion = inferSolcVersion;
const isInitCodeMatch = (actualInitCodeWithArgs, artifact) => {
    const coder = ethers_1.ethers.AbiCoder.defaultAbiCoder();
    const artifactBytecodeLength = (0, utils_1.getBytesLength)(artifact.bytecode);
    const actualInitCodeLength = (0, utils_1.getBytesLength)(actualInitCodeWithArgs);
    if (artifactBytecodeLength > actualInitCodeLength) {
        return false;
    }
    const actualInitCodeNoArgs = ethers_1.ethers.dataSlice(actualInitCodeWithArgs, 0, artifactBytecodeLength);
    const encodedArgs = ethers_1.ethers.dataSlice(actualInitCodeWithArgs, artifactBytecodeLength);
    if (artifact.constructorFragment) {
        try {
            coder.decode(artifact.constructorFragment.inputs, encodedArgs);
        }
        catch {
            return false;
        }
    }
    else if (artifactBytecodeLength !== actualInitCodeLength) {
        return false;
    }
    const artifactInitCodeNoLibraries = (0, utils_1.zeroOutLibraryReferences)(artifact.bytecode, artifact.linkReferences);
    const actualInitCodeNoLibraries = (0, utils_1.zeroOutLibraryReferences)(actualInitCodeNoArgs, artifact.linkReferences);
    return (artifactInitCodeNoLibraries.toLowerCase() ===
        actualInitCodeNoLibraries.toLowerCase());
};
exports.isInitCodeMatch = isInitCodeMatch;
const getSphinxConfigFromScript = async (scriptPath, sphinxPluginTypesInterface, targetContract, spinner) => {
    const json = await (0, exports.callForgeScriptFunction)(scriptPath, 'sphinxConfigABIEncoded()', [], undefined, targetContract, spinner);
    const returned = json.returns[0].value;
    const coder = ethers_1.ethers.AbiCoder.defaultAbiCoder();
    const sphinxConfigFragment = (0, exports.findFunctionFragment)(sphinxPluginTypesInterface, 'sphinxConfigType');
    const decoded = coder.decode([...sphinxConfigFragment.outputs, 'address', 'address'], returned);
    const { sphinxConfig } = (0, contracts_1.recursivelyConvertResult)(sphinxConfigFragment.outputs, decoded);
    const parsed = {
        projectName: sphinxConfig.projectName,
        owners: (0, utils_1.sortHexStrings)(sphinxConfig.owners),
        threshold: sphinxConfig.threshold.toString(),
        orgId: sphinxConfig.orgId,
        testnets: sphinxConfig.testnets,
        mainnets: sphinxConfig.mainnets,
        saltNonce: sphinxConfig.saltNonce.toString(),
        safeAddress: decoded[1],
        moduleAddress: decoded[2],
    };
    return parsed;
};
exports.getSphinxConfigFromScript = getSphinxConfigFromScript;
const getForgeScriptArgs = (scriptPath, signature, args, forkUrl, targetContract, silent = true, json = true, broadcast = false) => {
    const forgeScriptArgs = [
        'script',
        scriptPath,
        ...(forkUrl ? ['--rpc-url', forkUrl] : []),
        '--sig',
        signature,
        ...args,
    ];
    if (silent) {
        forgeScriptArgs.push('--silent');
    }
    if (json) {
        forgeScriptArgs.push('--json');
    }
    if (broadcast) {
        forgeScriptArgs.push('--broadcast');
    }
    if (targetContract) {
        forgeScriptArgs.push('--target-contract', targetContract);
    }
    return forgeScriptArgs;
};
exports.getForgeScriptArgs = getForgeScriptArgs;
const callForgeScriptFunction = async (scriptPath, signature, args, forkUrl, targetContract, spinner) => {
    const testScriptArgs = (0, exports.getForgeScriptArgs)(scriptPath, signature, args, forkUrl, targetContract, false, false);
    const { code: testCode, stdout: testOut, stderr: testErr, } = await (0, utils_1.spawnAsync)('forge', testScriptArgs, {
        FOUNDRY_BUILD_INFO: 'false',
    });
    if (testCode !== 0) {
        spinner?.stop();
        console.log(testOut);
        console.log(testErr);
        process.exit(1);
    }
    const forgeScriptArgs = (0, exports.getForgeScriptArgs)(scriptPath, signature, args, forkUrl, targetContract, true, true);
    const { code, stdout, stderr } = await (0, utils_1.spawnAsync)('forge', forgeScriptArgs, {
        FOUNDRY_BUILD_INFO: 'false',
    });
    if (code !== 0) {
        spinner?.stop();
        console.log(stdout);
        console.log(stderr);
        process.exit(1);
    }
    try {
        return JSON.parse(stdout);
    }
    catch {
        throw new Error(`Failed to parse Foundry output. Reason:\n${stdout}`);
    }
};
exports.callForgeScriptFunction = callForgeScriptFunction;
const isFoundryMultiChainDryRun = (dryRun) => {
    const multiChainDryRun = dryRun;
    return (Array.isArray(multiChainDryRun.deployments) &&
        !(0, exports.isFoundrySingleChainDryRun)(dryRun));
};
exports.isFoundryMultiChainDryRun = isFoundryMultiChainDryRun;
const isFoundrySingleChainDryRun = (dryRun) => {
    const singleChainDryRun = dryRun;
    return (Array.isArray(singleChainDryRun.transactions) &&
        Array.isArray(singleChainDryRun.receipts) &&
        Array.isArray(singleChainDryRun.libraries));
};
exports.isFoundrySingleChainDryRun = isFoundrySingleChainDryRun;
const readFoundryMultiChainDryRun = (broadcastFolder, scriptPath, functionNameOrSelector, timeThreshold) => {
    const dryRunPath = (0, path_1.join)(broadcastFolder, 'multi', 'dry-run', `${(0, path_1.basename)(scriptPath)}-latest`, `${functionNameOrSelector}.json`);
    if ((0, fs_1.existsSync)(dryRunPath) && (0, fs_1.statSync)(dryRunPath).mtime > timeThreshold) {
        return JSON.parse((0, fs_1.readFileSync)(dryRunPath, 'utf8'));
    }
    else {
        return undefined;
    }
};
exports.readFoundryMultiChainDryRun = readFoundryMultiChainDryRun;
const getFoundrySingleChainDryRunPath = (broadcastFolder, scriptPath, chainId, functionNameOrSelector) => {
    return (0, path_1.join)(broadcastFolder, (0, path_1.basename)(scriptPath), chainId.toString(), 'dry-run', `${functionNameOrSelector}-latest.json`);
};
exports.getFoundrySingleChainDryRunPath = getFoundrySingleChainDryRunPath;
const readFoundrySingleChainBroadcast = (broadcastFolder, scriptPath, chainId, functionNameOrSelector, timeThreshold) => {
    const broadcastFilePath = (0, path_1.join)(broadcastFolder, (0, path_1.basename)(scriptPath), chainId.toString(), `${functionNameOrSelector}-latest.json`);
    if ((0, fs_1.existsSync)(broadcastFilePath) &&
        (0, fs_1.statSync)(broadcastFilePath).mtime > timeThreshold) {
        return JSON.parse((0, fs_1.readFileSync)(broadcastFilePath, 'utf8'));
    }
    else {
        return undefined;
    }
};
exports.readFoundrySingleChainBroadcast = readFoundrySingleChainBroadcast;
const readFoundrySingleChainDryRun = (broadcastFolder, scriptPath, chainId, functionNameOrSelector, timeThreshold) => {
    const dryRunPath = (0, exports.getFoundrySingleChainDryRunPath)(broadcastFolder, scriptPath, chainId.toString(), functionNameOrSelector);
    if ((0, fs_1.existsSync)(dryRunPath) && (0, fs_1.statSync)(dryRunPath).mtime > timeThreshold) {
        return JSON.parse((0, fs_1.readFileSync)(dryRunPath, 'utf8'));
    }
    else {
        return undefined;
    }
};
exports.readFoundrySingleChainDryRun = readFoundrySingleChainDryRun;
const readInterface = (artifactFolder, contractName) => {
    const abi = require(path_1.default.resolve(`${artifactFolder}/${contractName}.sol/${contractName}.json`)).abi;
    return new ethers_1.ethers.Interface(abi);
};
exports.readInterface = readInterface;
const findFunctionFragment = (iface, fragmentName) => {
    const functionFragment = iface.fragments
        .filter(ethers_1.ethers.Fragment.isFunction)
        .find((fragment) => fragment.name === fragmentName);
    if (!functionFragment) {
        throw new Error(`Fragment not found in ABI.`);
    }
    return functionFragment;
};
exports.findFunctionFragment = findFunctionFragment;
const convertLibraryFormat = (librariesArray) => {
    return librariesArray.map((libraryString) => {
        const parts = libraryString.split(/[:=]/);
        if (parts.length !== 3) {
            throw new Error('Invalid library string format.');
        }
        const [filePath, contractName, address] = parts;
        return `${filePath}:${contractName}=${ethers_1.ethers.getAddress(address)}`;
    });
};
exports.convertLibraryFormat = convertLibraryFormat;
const toSphinxTransactionEstimatedGas = (response) => {
    return {
        to: response.to,
        from: response.from,
        data: response.data,
        gasLimit: response.gasLimit.toString(),
        gasPrice: response.gasPrice.toString(),
        value: response.value.toString(),
        chainId: response.chainId.toString(),
    };
};
const getEstimatedGas = async (transactions, provider) => {
    const estimatedMinGasLimit = await provider.estimateGas({
        to: ethers_1.ethers.ZeroAddress,
        data: '0x',
    });
    const adjustedGasLimit = Number(estimatedMinGasLimit) - 21000;
    const transactionsWithGasEstimates = transactions
        .map((transaction) => {
        return {
            transaction: toSphinxTransactionEstimatedGas(transaction.response),
            estimatedGas: Math.round(Number(transaction.receipt.gasUsed) * 1.3),
        };
    })
        .map((transactionWithEstimatedGas) => {
        const gasWithBuffer = transactionWithEstimatedGas.estimatedGas;
        const totalGas = gasWithBuffer + adjustedGasLimit;
        if (totalGas < 0) {
            throw new Error('Gas used is less than 0. Should never happen.');
        }
        return {
            transaction: transactionWithEstimatedGas.transaction,
            estimatedGas: totalGas.toString(),
        };
    });
    const estimatedGas = transactionsWithGasEstimates
        .map((receiptWithEstimatedGas) => receiptWithEstimatedGas.estimatedGas)
        .map(Number)
        .reduce((a, b) => a + b, 0);
    return {
        estimatedGas: estimatedGas.toString(),
        transactionsWithGasEstimates,
    };
};
exports.getEstimatedGas = getEstimatedGas;
const getNetworkGasEstimate = async (deploymentConfig, chainId, rpcUrl) => {
    const { transactions } = await (0, simulate_1.simulate)(deploymentConfig, chainId, rpcUrl);
    const provider = new core_1.SphinxJsonRpcProvider(rpcUrl);
    const { estimatedGas, transactionsWithGasEstimates } = await (0, exports.getEstimatedGas)(transactions, provider);
    const networkConfig = (0, utils_1.fetchNetworkConfigFromDeploymentConfig)(BigInt(chainId), deploymentConfig);
    return {
        chainId: Number(chainId),
        estimatedGas,
        transactions: transactionsWithGasEstimates,
        fundsRequested: networkConfig.safeFundingRequest?.fundsRequested ?? '0',
    };
};
exports.getNetworkGasEstimate = getNetworkGasEstimate;
const replaceEnvVariables = (input) => {
    const envVarRegex = /\$\{((\w|\s)+)\}/g;
    const replaceEnvVar = (str) => {
        return str.trim().replace(envVarRegex, (_, envVar) => {
            return process.env[envVar.trim()] || '';
        });
    };
    if (typeof input === 'string') {
        return replaceEnvVar(input);
    }
    else if (Array.isArray(input)) {
        return input.map((element) => (0, exports.replaceEnvVariables)(element));
    }
    else if (typeof input === 'object' && input !== null) {
        const result = {};
        for (const key in input) {
            if (input.hasOwnProperty(key)) {
                result[key] = (0, exports.replaceEnvVariables)(input[key]);
            }
        }
        return result;
    }
    else {
        return input;
    }
};
exports.replaceEnvVariables = replaceEnvVariables;
const findFullyQualifiedNameForInitCode = (initCodeWithArgs, configArtifacts) => {
    for (const fullyQualifiedName of Object.keys(configArtifacts)) {
        const { artifact } = configArtifacts[fullyQualifiedName];
        const { bytecode, linkReferences, abi } = artifact;
        const iface = new ethers_1.ethers.Interface(abi);
        const constructorFragment = iface.fragments.find(ethers_1.ConstructorFragment.isFragment);
        if ((0, exports.isInitCodeMatch)(initCodeWithArgs, {
            bytecode,
            linkReferences,
            constructorFragment,
        })) {
            return fullyQualifiedName;
        }
    }
    return undefined;
};
exports.findFullyQualifiedNameForInitCode = findFullyQualifiedNameForInitCode;
const findFullyQualifiedNameForAddress = (address, accountAccesses, configArtifacts) => {
    const flat = accountAccesses.flatMap((access) => [
        access.root,
        ...access.nested,
    ]);
    const createAccountAccess = flat.find((accountAccess) => accountAccess.kind === contracts_1.AccountAccessKind.Create &&
        accountAccess.account === address);
    if (createAccountAccess) {
        const initCodeWithArgs = createAccountAccess.data;
        return (0, exports.findFullyQualifiedNameForInitCode)(initCodeWithArgs, configArtifacts);
    }
    else {
        return undefined;
    }
};
exports.findFullyQualifiedNameForAddress = findFullyQualifiedNameForAddress;
const writeSystemContracts = (sphinxPluginTypesInterface, cachePath) => {
    const systemContractsArrayFragment = (0, exports.findFunctionFragment)(sphinxPluginTypesInterface, 'systemContractInfoArrayType');
    const coder = ethers_1.ethers.AbiCoder.defaultAbiCoder();
    const filePath = (0, path_1.join)(cachePath, 'sphinx-system-contracts.txt');
    const encodedSystemContractArray = coder.encode(systemContractsArrayFragment.outputs, [(0, contracts_1.getSystemContractInfo)()]);
    (0, fs_1.writeFileSync)(filePath, encodedSystemContractArray);
    return filePath;
};
exports.writeSystemContracts = writeSystemContracts;
const isCreate2AccountAccess = (root, nested) => {
    if (nested.length === 0) {
        return false;
    }
    const nextAccountAccess = nested[0];
    const isCreate2Call = root.kind === contracts_1.AccountAccessKind.Call &&
        root.account === contracts_1.DETERMINISTIC_DEPLOYMENT_PROXY_ADDRESS &&
        (0, utils_1.getBytesLength)(root.data) >= 32;
    if (!isCreate2Call) {
        return false;
    }
    const { create2Address } = (0, utils_1.decodeDeterministicDeploymentProxyData)(root.data);
    return (nextAccountAccess.kind === contracts_1.AccountAccessKind.Create &&
        nextAccountAccess.accessor === contracts_1.DETERMINISTIC_DEPLOYMENT_PROXY_ADDRESS &&
        nextAccountAccess.account === create2Address);
};
exports.isCreate2AccountAccess = isCreate2AccountAccess;
const parseNestedContractDeployments = (nested, configArtifacts) => {
    const parsedContracts = [];
    const unlabeled = [];
    for (const accountAccess of nested) {
        if (accountAccess.kind === contracts_1.AccountAccessKind.Create) {
            const initCodeWithArgs = accountAccess.data;
            const address = accountAccess.account;
            const fullyQualifiedName = (0, exports.findFullyQualifiedNameForInitCode)(initCodeWithArgs, configArtifacts);
            if (fullyQualifiedName) {
                parsedContracts.push({
                    address,
                    initCodeWithArgs,
                    fullyQualifiedName,
                });
            }
            else {
                unlabeled.push({
                    address,
                    initCodeWithArgs,
                });
            }
        }
    }
    return { parsedContracts, unlabeled };
};
exports.parseNestedContractDeployments = parseNestedContractDeployments;
const assertValidVersions = async (scriptPath, targetContract) => {
    (0, utils_2.assertValidNodeVersion)();
    const output = await (0, exports.callForgeScriptFunction)(scriptPath, 'sphinxValidate()', ['--always-use-create-2-factory'], undefined, targetContract);
    const libraryVersion = output.returns.libraryVersion.value
        .slice(1, -1);
    const forkInstalled = output.returns.forkInstalled.value;
    if (libraryVersion !== contracts_1.CONTRACTS_LIBRARY_VERSION) {
        throw Error(`The version of the Sphinx library contracts does not match the Sphinx plugin version. Please\n` +
            `update the library contracts by running the command:\n` +
            `npx sphinx install`);
    }
    if (forkInstalled === 'false') {
        throw new Error(`Detected invalid Foundry version. Please update to the latest version of Foundry by running:\n` +
            `foundryup`);
    }
};
exports.assertValidVersions = assertValidVersions;
const isDeploymentInfo = (obj) => {
    return (typeof obj === 'object' &&
        obj !== null &&
        (0, utils_1.isNormalizedAddress)(obj.safeAddress) &&
        (0, utils_1.isNormalizedAddress)(obj.moduleAddress) &&
        typeof obj.requireSuccess === 'boolean' &&
        (0, utils_1.isNormalizedAddress)(obj.executorAddress) &&
        typeof obj.nonce === 'string' &&
        typeof obj.chainId === 'string' &&
        typeof obj.blockGasLimit === 'string' &&
        typeof obj.safeInitData === 'string' &&
        isSphinxConfig(obj.newConfig) &&
        isExecutionMode(obj.executionMode) &&
        isInitialChainState(obj.initialState) &&
        typeof obj.arbitraryChain === 'boolean' &&
        typeof obj.sphinxLibraryVersion === 'string' &&
        Array.isArray(obj.accountAccesses) &&
        obj.accountAccesses.every(isParsedAccountAccess) &&
        Array.isArray(obj.gasEstimates) &&
        obj.gasEstimates.every((e) => typeof e === 'string'));
};
exports.isDeploymentInfo = isDeploymentInfo;
const isSphinxConfig = (obj) => {
    return (typeof obj === 'object' &&
        obj !== null &&
        typeof obj.projectName === 'string' &&
        typeof obj.orgId === 'string' &&
        Array.isArray(obj.owners) &&
        obj.owners.every((o) => (0, utils_1.isNormalizedAddress)(o)) &&
        Array.isArray(obj.mainnets) &&
        obj.mainnets.every((m) => typeof m === 'string') &&
        Array.isArray(obj.testnets) &&
        obj.testnets.every((t) => typeof t === 'string') &&
        typeof obj.threshold === 'string' &&
        typeof obj.saltNonce === 'string');
};
const isExecutionMode = (obj) => {
    return Object.values(core_1.ExecutionMode).includes(obj);
};
const isInitialChainState = (obj) => {
    return (typeof obj === 'object' &&
        obj !== null &&
        typeof obj.isSafeDeployed === 'boolean' &&
        typeof obj.isModuleDeployed === 'boolean' &&
        typeof obj.isExecuting === 'boolean');
};
const isParsedAccountAccess = (obj) => {
    return (typeof obj === 'object' &&
        obj !== null &&
        isAccountAccess(obj.root) &&
        Array.isArray(obj.nested) &&
        obj.nested.every(isAccountAccess));
};
const isAccountAccess = (obj) => {
    return (typeof obj === 'object' &&
        obj !== null &&
        typeof obj.chainInfo === 'object' &&
        obj.chainInfo !== null &&
        typeof obj.chainInfo.forkId === 'string' &&
        typeof obj.chainInfo.chainId === 'string' &&
        Object.values(contracts_1.AccountAccessKind).includes(obj.kind) &&
        typeof obj.account === 'string' &&
        typeof obj.accessor === 'string' &&
        typeof obj.initialized === 'boolean' &&
        typeof obj.oldBalance === 'string' &&
        typeof obj.newBalance === 'string' &&
        typeof obj.deployedCode === 'string' &&
        typeof obj.value === 'string' &&
        typeof obj.data === 'string' &&
        typeof obj.reverted === 'boolean' &&
        Array.isArray(obj.storageAccesses) &&
        obj.storageAccesses.every(isStorageAccess));
};
const isStorageAccess = (obj) => {
    return (typeof obj === 'object' &&
        obj !== null &&
        typeof obj.account === 'string' &&
        typeof obj.slot === 'string' &&
        typeof obj.isWrite === 'boolean' &&
        typeof obj.previousValue === 'string' &&
        typeof obj.newValue === 'string' &&
        typeof obj.reverted === 'boolean');
};
const parseScriptFunctionCalldata = async (sig, spawnAsyncFunction = utils_1.spawnAsync) => {
    if (sig.length === 0) {
        throw new Error(error_messages_1.SigCalledWithNoArgsErrorMessage);
    }
    if ((0, utils_1.hasParentheses)(sig[0])) {
        const selectorOutput = await spawnAsyncFunction(`cast`, ['sig', sig[0]]);
        if (selectorOutput.code !== 0) {
            throw new Error(selectorOutput.stderr);
        }
        const abiEncodeOutput = await spawnAsyncFunction(`cast`, [
            'abi-encode',
            ...sig,
        ]);
        if (abiEncodeOutput.code !== 0) {
            throw new Error(abiEncodeOutput.stderr);
        }
        const trimmedSelector = selectorOutput.stdout.replace(/\n/g, '');
        const trimmedAbiEncodedData = abiEncodeOutput.stdout.replace(/\n/g, '');
        const calldata = ethers_1.ethers.concat([trimmedSelector, trimmedAbiEncodedData]);
        return calldata;
    }
    else if (sig.length === 1) {
        const trimmed = (0, utils_1.trimQuotes)(sig[0]);
        const with0x = (0, contracts_1.add0x)(trimmed);
        if ((0, utils_1.isDataHexString)(with0x)) {
            return (0, contracts_1.add0x)(trimmed);
        }
    }
    throw new Error(error_messages_1.InvalidFirstSigArgumentErrorMessage);
};
exports.parseScriptFunctionCalldata = parseScriptFunctionCalldata;
const validateProposalNetworks = async (cliNetworks, configTestnets, configMainnets, rpcEndpoints, isLiveNetwork) => {
    if (cliNetworks.length === 0) {
        throw new Error(`Expected at least one network, but none were supplied.`);
    }
    let resolvedNetworks;
    if (cliNetworks.length === 1 && cliNetworks[0] === 'mainnets') {
        if (configMainnets.length === 0) {
            throw new Error(`Your 'sphinxConfig.mainnets' array must contain at least one network when\n` +
                `you use the '--mainnets' flag.`);
        }
        resolvedNetworks = configMainnets;
    }
    else if (cliNetworks.length === 1 && cliNetworks[0] === 'testnets') {
        if (configTestnets.length === 0) {
            throw new Error(`Your 'sphinxConfig.testnets' array must contain at least one network when\n` +
                `you use the '--testnets' flag.`);
        }
        resolvedNetworks = configTestnets;
    }
    else {
        resolvedNetworks = cliNetworks;
    }
    const networkPromises = resolvedNetworks.map(async (network) => {
        const rpcUrl = rpcEndpoints[network];
        if (!rpcUrl) {
            return { type: 'missingEndpoint', network };
        }
        const provider = new core_1.SphinxJsonRpcProvider(rpcUrl);
        let networkInfo;
        try {
            networkInfo = await provider.getNetwork();
        }
        catch {
            return { type: 'failedRequest', network };
        }
        const sphinxNetwork = contracts_1.SPHINX_NETWORKS.find((supportedNetwork) => supportedNetwork.chainId === networkInfo.chainId);
        if (!sphinxNetwork) {
            return {
                type: 'unsupported',
                network,
                chainId: networkInfo.chainId.toString(),
            };
        }
        if (!(await isLiveNetwork(provider))) {
            return { type: 'localNetwork', network };
        }
        return {
            type: 'valid',
            rpcUrl,
            network,
            networkType: sphinxNetwork.networkType,
        };
    });
    const results = await Promise.allSettled(networkPromises);
    const missingEndpoint = [];
    const failedRequest = [];
    const unsupported = [];
    const localNetwork = [];
    const valid = [];
    for (const result of results) {
        if (result.status === 'rejected') {
            throw new Error(`Promise was rejected. Should never happen.`);
        }
        const value = result.value;
        if (value.type === 'missingEndpoint') {
            missingEndpoint.push(value.network);
        }
        else if (value.type === 'failedRequest') {
            failedRequest.push(value.network);
        }
        else if (value.type === 'unsupported') {
            if (value.chainId === undefined) {
                throw new Error(`Chain ID is undefined. Should never happen.`);
            }
            unsupported.push({ networkName: value.network, chainId: value.chainId });
        }
        else if (value.type === 'localNetwork') {
            localNetwork.push(value.network);
        }
        else if (value.type === 'valid') {
            const { rpcUrl, network, networkType } = value;
            if (rpcUrl === undefined ||
                network === undefined ||
                networkType === undefined) {
                throw new Error(`Network field(s) are undefined. Should never happen.`);
            }
            valid.push({ rpcUrl, network, networkType });
        }
        else {
            throw new Error(`Unknown result: ${value.type}. Should never happen.`);
        }
    }
    if (missingEndpoint.length > 0) {
        throw new Error((0, error_messages_1.getMissingEndpointErrorMessage)(missingEndpoint));
    }
    if (failedRequest.length > 0) {
        throw new Error((0, error_messages_1.getFailedRequestErrorMessage)(failedRequest));
    }
    if (unsupported.length > 0) {
        throw new Error((0, error_messages_1.getUnsupportedNetworkErrorMessage)(unsupported));
    }
    if (localNetwork.length > 0) {
        throw new Error((0, error_messages_1.getLocalNetworkErrorMessage)(localNetwork));
    }
    const networkTypes = valid.map(({ networkType }) => networkType);
    const isMixed = (0, utils_1.isArrayMixed)(networkTypes);
    if (isMixed) {
        throw new Error((0, error_messages_1.getMixedNetworkTypeErrorMessage)(valid));
    }
    const isTestnet = networkTypes.every((networkType) => networkType === 'Testnet');
    if (cliNetworks.length === 1 && cliNetworks[0] === 'mainnets' && isTestnet) {
        throw new Error(error_messages_1.SphinxConfigMainnetsContainsTestnetsErrorMessage);
    }
    else if (cliNetworks.length === 1 &&
        cliNetworks[0] === 'testnets' &&
        !isTestnet) {
        throw new Error(error_messages_1.SphinxConfigTestnetsContainsMainnetsErrorMessage);
    }
    const rpcUrls = valid.map(({ rpcUrl }) => rpcUrl);
    return { rpcUrls, isTestnet };
};
exports.validateProposalNetworks = validateProposalNetworks;
//# sourceMappingURL=index.js.map